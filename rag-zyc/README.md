# å­¦æœ¯ç»¼è¿°è‡ªåŠ¨ç”Ÿæˆç³»ç»Ÿ

ç«¯åˆ°ç«¯å­¦æœ¯æ–‡çŒ®ç»¼è¿°ç”Ÿæˆç³»ç»Ÿï¼ŒåŒ…å« Writing Agent ä¸ Judge Agentã€‚

## ğŸ“¦ é¡¹ç›®ç»“æ„

```
/Users/zyc/Desktop/rag/
â”œâ”€â”€ writing_agent.py           # Writing Agent æ ¸å¿ƒå®ç°
â”œâ”€â”€ judge_agent.py             # Judge Agent æ ¸å¿ƒå®ç°
â”œâ”€â”€ pipeline_adapter.py        # å°†æ£€ç´¢/åˆ†æè¾“å‡ºè½¬æ¢ä¸ºå†™ä½œè¾“å…¥
â”œâ”€â”€ model_config.json          # æ¨¡å‹é…ç½®æ–‡ä»¶
â”œâ”€â”€ test_full_pipeline.py      # å®Œæ•´ç¤ºä¾‹è„šæœ¬ï¼ˆæ”¯æŒæ¥å…¥å‰åº Analysis JSONï¼‰
â””â”€â”€ README.md                  # æœ¬æ–‡æ¡£
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### Writing Agentï¼ˆå†™ä½œä»£ç†ï¼‰
- âœ… å°†ç»“æ„åŒ–ç ”ç©¶æ‘˜è¦è½¬åŒ–ä¸ºå­¦æœ¯ç»¼è¿°
- âœ… æ”¯æŒå¤šæ¸©åº¦é‡‡æ ·ç”Ÿæˆå¤šæ ·æ€§å€™é€‰
- âœ… 4ç§å†™ä½œé£æ ¼ï¼ˆå™è¿°ã€è¡¨æ ¼ã€æ—¶é—´çº¿ã€åˆ†ç±»ï¼‰
- âœ… è‡ªæˆ‘ä¿®æ­£æœºåˆ¶ï¼ˆReflectionï¼‰
- âœ… å¼•ç”¨è¿½è¸ªå’ŒéªŒè¯
- âœ… åŒæ­¥/å¼‚æ­¥å¹¶è¡Œç”Ÿæˆ

### Judge Agentï¼ˆè¯„åˆ†ä»£ç†ï¼‰
- âœ… 5ç»´åº¦è¯„åˆ†ç³»ç»Ÿï¼ˆè¦†ç›–åº¦ã€å‡†ç¡®æ€§ã€è¿è´¯æ€§ã€å­¦æœ¯æ€§ã€æ–°é¢–æ€§ï¼‰
- âœ… è¯¦ç»†åé¦ˆï¼ˆä¼˜ç‚¹ã€ç¼ºç‚¹ã€æ”¹è¿›å»ºè®®ï¼‰
- âœ… æ‹’ç»é‡‡æ ·ï¼ˆè¿‡æ»¤ä½è´¨é‡è‰ç¨¿ï¼‰
- âœ… äº‹å®å‡†ç¡®æ€§éªŒè¯
- âœ… å¼•ç”¨æœ‰æ•ˆæ€§æ£€æŸ¥

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install openai
```

### 2. é…ç½®æ¨¡å‹

ç¼–è¾‘ `model_config.json` æˆ–ç›´æ¥åœ¨ä»£ç ä¸­é…ç½®ï¼š

```python
from writing_agent import ModelConfig

config = ModelConfig(
    name="Kimi-K2",  # æ¨¡å‹åç§°
    api_key="your-api-key-here",
    base_url="https://llmapi.paratera.com/v1/",
    temperature=0.5,
    max_tokens=4096
)
```

**æ”¯æŒçš„æ¨¡å‹**ï¼šKimiã€Qwenã€DeepSeekã€GLMã€Doubao ç­‰

### 3. è¿è¡Œç¤ºä¾‹ï¼ˆå¯æ¥å…¥å‰åºæ£€ç´¢/åˆ†æï¼‰

```bash
# æƒ…å†µ Aï¼šå·²æœ‰ Analysis é˜¶æ®µ JSONï¼ˆåŒ…å« clusters/insights/datasï¼‰
python test_full_pipeline.py --analysis-json /path/to/analysis_result.json

# æƒ…å†µ Bï¼šæ— å‰åºç»“æœï¼Œä½¿ç”¨å†…ç½®ç¤ºä¾‹æ•°æ®
python test_full_pipeline.py
```

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### å‰åºæ¨¡å—å¯¹æ¥è¯´æ˜
- ä½¿ç”¨ Retrieval/Analysis å¾—åˆ°çš„ JSONï¼ˆå« `clusters`/`insights`/`datas`ï¼‰ï¼Œè°ƒç”¨ `pipeline_adapter.analysis_to_cluster_summaries` è½¬ä¸º `cluster_summaries`ã€‚
- `test_full_pipeline.py` å·²å†…ç½®è½¬æ¢ï¼Œä¼ å…¥ `--analysis-json` å³å¯ç›´æ¥è¿è¡Œã€‚

### ç¤ºä¾‹ 1: ç”Ÿæˆå­¦æœ¯ç»¼è¿°

```python
from writing_agent import WritingAgent, ModelConfig

# é…ç½®æ¨¡å‹
config = ModelConfig(
    name="Kimi-K2",
    api_key="sk-your-api-key",
    base_url="https://llmapi.paratera.com/v1/"
)

# åˆ›å»º Writing Agent
writer = WritingAgent(config, style="narrative")

# å‡†å¤‡è¾“å…¥æ•°æ®
cluster_summaries = {
    "cluster_1": {
        "topic": "Transformer æ¶æ„",
        "summary": "å…³äº Transformer æ¶æ„çš„ç ”ç©¶",
        "papers": [
            {
                "paper_id": "paper_001",
                "title": "Attention is All You Need",
                "authors": ["Vaswani et al."],
                "year": 2017,
                "key_contribution": "æå‡º Transformer æ¶æ„"
            }
            # æ›´å¤šè®ºæ–‡...
        ]
    }
}

# ç”Ÿæˆè‰ç¨¿
draft = writer.generate_draft(cluster_summaries)
print(draft["content"])
```

### ç¤ºä¾‹ 2: è¯„ä¼°è‰ç¨¿è´¨é‡

```python
from judge_agent import JudgeAgent, ModelConfig

# é…ç½® Judgeï¼ˆä½¿ç”¨ä½æ¸©åº¦ä¿è¯è¯„åˆ†ä¸€è‡´æ€§ï¼‰
judge_config = ModelConfig(
    name="Kimi-K2",
    api_key="sk-your-api-key",
    base_url="https://llmapi.paratera.com/v1/",
    temperature=0.2  # Judge ä½¿ç”¨ä½æ¸©åº¦
)

# åˆ›å»º Judge Agent
judge = JudgeAgent(judge_config)

# è¯„ä¼°è‰ç¨¿
evaluation = judge.evaluate_draft(draft["content"])

# æŸ¥çœ‹ç»“æœ
print(f"æ€»åˆ†: {evaluation['overall_score']:.1f}/100")
print(f"ä¼˜ç‚¹: {evaluation['strengths']}")
print(f"ç¼ºç‚¹: {evaluation['weaknesses']}")
print(f"æ”¹è¿›å»ºè®®: {evaluation['improvement_suggestions']}")
```

### ç¤ºä¾‹ 3: å®Œæ•´æµç¨‹

```python
from writing_agent import WritingAgent, ModelConfig
from judge_agent import JudgeAgent

# 1. é…ç½®æ¨¡å‹
writing_config = ModelConfig(
    name="Kimi-K2",
    api_key="sk-your-api-key",
    base_url="https://llmapi.paratera.com/v1/",
    temperature=0.5
)

judge_config = ModelConfig(
    name="Kimi-K2",
    api_key="sk-your-api-key",
    base_url="https://llmapi.paratera.com/v1/",
    temperature=0.2
)

# 2. åˆ›å»º Agents
writer = WritingAgent(writing_config)
judge = JudgeAgent(judge_config)

# 3. ç”Ÿæˆå¤šä¸ªå€™é€‰è‰ç¨¿
candidates = writer.generate_multiple_candidates(
    cluster_summaries=cluster_summaries,
    num_candidates=3,
    temperature_range=(0.3, 0.7)
)

# 4. è¯„ä¼°å’Œæ‹©ä¼˜
selected = judge.rejection_sampling(
    drafts=[c["content"] for c in candidates],
    reference=cluster_summaries,
    threshold=70.0,  # æœ€ä½åˆ†æ•°é˜ˆå€¼
    max_keep=2       # æœ€å¤šä¿ç•™æ•°é‡
)

# 5. é€‰æ‹©æœ€ä½³è‰ç¨¿
best = selected[0]
print(f"æœ€ä½³è‰ç¨¿å¾—åˆ†: {best['overall_score']:.1f}/100")

# 6. åŸºäºåé¦ˆæ”¹è¿›ï¼ˆå¯é€‰ï¼‰
if best['overall_score'] < 85:
    feedback = {"improvements": best['improvement_suggestions']}
    refined = writer.refine_draft(best['draft'], feedback)

    # é‡æ–°è¯„ä¼°
    final_eval = judge.evaluate_draft(refined["content"])
    print(f"æ”¹è¿›åå¾—åˆ†: {final_eval['overall_score']:.1f}/100")

# 7. éªŒè¯äº‹å®å‡†ç¡®æ€§
evidence = {}
for cluster_data in cluster_summaries.values():
    for paper in cluster_data.get('papers', []):
        evidence[paper['paper_id']] = paper

verification = judge.verify_factuality(best['draft'], evidence)
print(f"äº‹å®å‡†ç¡®ç‡: {verification.get('accuracy_rate', 0):.1%}")
print(f"å¼•ç”¨æœ‰æ•ˆç‡: {verification['citation_check']['citation_validity_rate']:.1%}")
```

---

## ğŸ“Š è¯„åˆ†æ ‡å‡†

### Judge Agent è¯„åˆ†ç»´åº¦

| ç»´åº¦ | æƒé‡ | è¯´æ˜ |
|-----|------|-----|
| **è¦†ç›–åº¦** (Coverage) | 25% | æ˜¯å¦åŒ…å«æ‰€æœ‰é‡è¦è®ºæ–‡å’Œæ¦‚å¿µ |
| **å‡†ç¡®æ€§** (Factuality) | 30% | äº‹å®é™ˆè¿°æ˜¯å¦å‡†ç¡®ï¼Œå¼•ç”¨æ˜¯å¦æ­£ç¡® |
| **è¿è´¯æ€§** (Coherence) | 20% | é€»è¾‘æµç¨‹æ˜¯å¦æ¸…æ™°ï¼Œè¿‡æ¸¡æ˜¯å¦è‡ªç„¶ |
| **å­¦æœ¯æ€§** (Academic Style) | 15% | æ˜¯å¦ç¬¦åˆå­¦æœ¯å†™ä½œè§„èŒƒ |
| **æ–°é¢–æ€§** (Novelty) | 10% | æ˜¯å¦è¯†åˆ«å‡ºç ”ç©¶è¶‹åŠ¿å’Œç©ºç™½ |

### è¯„åˆ†ç­‰çº§

| åˆ†æ•°èŒƒå›´ | ç­‰çº§ | è¯´æ˜ |
|---------|------|------|
| 90-100 | ä¼˜ç§€ | å¯å‘è¡¨è´¨é‡ï¼Œæ— éœ€ä¿®æ”¹æˆ–ä»…éœ€å¾®è°ƒ |
| 80-89 | è‰¯å¥½ | è´¨é‡è¾ƒé«˜ï¼Œéœ€å°å¹…ä¿®æ”¹ |
| 70-79 | åˆæ ¼ | åŸºæœ¬åˆæ ¼ï¼Œéœ€ä¸­ç­‰ç¨‹åº¦ä¿®æ”¹ |
| 60-69 | å°šå¯ | è´¨é‡ä¸€èˆ¬ï¼Œéœ€å¤§å¹…ä¿®æ”¹ |
| <60 | ä¸åˆæ ¼ | éœ€è¦é‡å†™ |

---

## ğŸ¨ é«˜çº§ç”¨æ³•

### 1. ç”Ÿæˆå¤šä¸ªå€™é€‰è‰ç¨¿

```python
# ä½¿ç”¨ä¸åŒæ¸©åº¦ç”Ÿæˆå¤šæ ·æ€§å€™é€‰
candidates = writer.generate_multiple_candidates(
    cluster_summaries=data,
    num_candidates=5,
    temperature_range=(0.3, 0.9)  # æ¸©åº¦èŒƒå›´
)

# æŸ¥çœ‹æ‰€æœ‰å€™é€‰
for candidate in candidates:
    print(f"å€™é€‰ {candidate['candidate_id']}: {len(candidate['content'])} å­—ç¬¦")
```

### 2. è‡ªæˆ‘ä¿®æ­£ï¼ˆReflectionï¼‰

```python
# ç”Ÿæˆåˆå§‹è‰ç¨¿
initial_draft = writer.generate_draft(cluster_summaries)

# å¤šè½®è‡ªæˆ‘ä¿®æ­£
refined_result = writer.refine_with_reflection(
    draft=initial_draft["content"],
    max_iterations=3  # æœ€å¤š 3 è½®
)

print(f"ç»è¿‡ {refined_result['iterations']} è½®ä¿®æ­£")
print(refined_result["final_draft"])
```

### 3. å¹¶è¡Œç”Ÿæˆï¼ˆå¼‚æ­¥ï¼Œæ›´å¿«ï¼‰

```python
import asyncio

async def parallel_generation():
    writer = WritingAgent(config)

    # å¹¶è¡Œç”Ÿæˆ 5 ä¸ªå€™é€‰ï¼ˆé€Ÿåº¦å¿« 5 å€ï¼‰
    candidates = await writer.generate_multiple_candidates_async(
        cluster_summaries=data,
        num_candidates=5
    )

    return candidates

# è¿è¡Œ
candidates = asyncio.run(parallel_generation())
```

### 4. æ‹’ç»é‡‡æ ·ï¼ˆè¿‡æ»¤ä½è´¨é‡ï¼‰

```python
# åªä¿ç•™é«˜è´¨é‡è‰ç¨¿
selected = judge.rejection_sampling(
    drafts=all_drafts,
    reference=cluster_summaries,
    threshold=70.0,  # è¿‡æ»¤ä½äº 70 åˆ†çš„
    max_keep=3       # æœ€å¤šä¿ç•™ 3 ä¸ª
)

print(f"ä» {len(all_drafts)} ä¸ªè‰ç¨¿ä¸­ä¿ç•™äº† {len(selected)} ä¸ªé«˜è´¨é‡è‰ç¨¿")
```

### 5. äº‹å®å‡†ç¡®æ€§éªŒè¯

```python
# å‡†å¤‡è¯æ®ææ–™
evidence = {
    "paper_001": {
        "title": "Attention is All You Need",
        "year": 2017,
        "key_facts": ["æå‡º Transformer", "åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶"]
    }
}

# éªŒè¯è‰ç¨¿
verification = judge.verify_factuality(draft["content"], evidence)

# æŸ¥çœ‹ç»“æœ
print(f"æ€»é™ˆè¿°æ•°: {verification.get('total_claims', 'N/A')}")
print(f"å‡†ç¡®ç‡: {verification.get('accuracy_rate', 0):.1%}")
print(f"å¼•ç”¨æœ‰æ•ˆç‡: {verification['citation_check']['citation_validity_rate']:.1%}")

if verification['citation_check']['invalid_citations']:
    print(f"æ— æ•ˆå¼•ç”¨: {verification['citation_check']['invalid_citations']}")
```

### 6. å¤šæ¨¡å‹æŠ•ç¥¨ï¼ˆæé«˜å¯é æ€§ï¼‰

```python
# ä½¿ç”¨å¤šä¸ªæ¨¡å‹è¯„åˆ†ï¼Œå–å¹³å‡å€¼
judges = [
    JudgeAgent(ModelConfig(name="Kimi-K2", api_key="...", base_url="...")),
    # å¯ä»¥æ·»åŠ å…¶ä»–æ¨¡å‹
]

scores = []
for judge in judges:
    evaluation = judge.evaluate_draft(draft)
    scores.append(evaluation['overall_score'])

final_score = sum(scores) / len(scores)
print(f"å¤šæ¨¡å‹å¹³å‡åˆ†: {final_score:.1f}/100")
```

### 7. ä¸åŒå†™ä½œé£æ ¼

```python
# å™è¿°å¼ï¼ˆé€‚åˆèƒŒæ™¯ä»‹ç»ï¼‰
agent_narrative = WritingAgent(config, style="narrative")

# è¡¨æ ¼é©±åŠ¨ï¼ˆé€‚åˆæ–¹æ³•å¯¹æ¯”ï¼‰
agent_table = WritingAgent(config, style="table-driven")

# æ—¶é—´çº¿å¼ï¼ˆé€‚åˆå‘å±•å†ç¨‹ï¼‰
agent_timeline = WritingAgent(config, style="timeline")

# åˆ†ç±»æ³•å¼ï¼ˆé€‚åˆæ–¹æ³•å½’ç±»ï¼‰
agent_taxonomy = WritingAgent(config, style="taxonomy")
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œ

```python
import asyncio

# æ…¢ï¼šä¸²è¡Œç”Ÿæˆ 5 ä¸ªè‰ç¨¿ â†’ è€—æ—¶ 5x
for i in range(5):
    draft = writer.generate_draft(data)

# å¿«ï¼šå¹¶è¡Œç”Ÿæˆ 5 ä¸ªè‰ç¨¿ â†’ è€—æ—¶ 1x
candidates = await writer.generate_multiple_candidates_async(data, 5)
```

### 2. ç»“æœç¼“å­˜

```python
import hashlib
import pickle

cache = {}

def cached_evaluate(judge, draft):
    """å¸¦ç¼“å­˜çš„è¯„ä¼°"""
    key = hashlib.md5(draft.encode()).hexdigest()

    if key in cache:
        print("[Cache hit]")
        return cache[key]

    result = judge.evaluate_draft(draft)
    cache[key] = result
    return result
```

### 3. æ‰¹é‡å¤„ç†

```python
# åˆ†æ‰¹å¤„ç†å¤§é‡è‰ç¨¿
batch_size = 10
for i in range(0, len(all_drafts), batch_size):
    batch = all_drafts[i:i+batch_size]
    results = await judge.rank_drafts_async(batch)
    # å¤„ç†ç»“æœ...
```

---

## ğŸ”§ API å‚è€ƒ

### WritingAgent ç±»

```python
class WritingAgent:
    def __init__(self, model_config: ModelConfig, style: str = "narrative")

    # ç”Ÿæˆå•ä¸ªè‰ç¨¿
    def generate_draft(
        self,
        cluster_summaries: Dict,
        temperature: Optional[float] = None
    ) -> Dict

    # å¼‚æ­¥ç”Ÿæˆ
    async def generate_draft_async(
        self,
        cluster_summaries: Dict,
        temperature: Optional[float] = None
    ) -> Dict

    # ç”Ÿæˆå¤šä¸ªå€™é€‰
    def generate_multiple_candidates(
        self,
        cluster_summaries: Dict,
        num_candidates: int = 3,
        temperature_range: Tuple[float, float] = (0.3, 0.9)
    ) -> List[Dict]

    # å¹¶è¡Œç”Ÿæˆå¤šä¸ªå€™é€‰
    async def generate_multiple_candidates_async(
        self,
        cluster_summaries: Dict,
        num_candidates: int = 3,
        temperature_range: Tuple[float, float] = (0.3, 0.9)
    ) -> List[Dict]

    # åŸºäºåé¦ˆæ”¹è¿›
    def refine_draft(self, draft: str, feedback: Dict) -> Dict

    # è‡ªæˆ‘æ‰¹è¯„
    def self_critique(self, draft: str) -> Dict

    # å¤šè½®è‡ªæˆ‘ä¿®æ­£
    def refine_with_reflection(
        self,
        draft: str,
        max_iterations: int = 3
    ) -> Dict

    # éªŒè¯å¼•ç”¨
    def validate_citations(
        self,
        draft: str,
        available_papers: Dict
    ) -> Dict
```

### JudgeAgent ç±»

```python
class JudgeAgent:
    def __init__(self, model_config: ModelConfig)

    # è¯„ä¼°å•ä¸ªè‰ç¨¿
    def evaluate_draft(
        self,
        draft: str,
        reference: Optional[Dict] = None
    ) -> Dict

    # å¼‚æ­¥è¯„ä¼°
    async def evaluate_draft_async(
        self,
        draft: str,
        reference: Optional[Dict] = None
    ) -> Dict

    # å¯¹å¤šä¸ªè‰ç¨¿æ’åº
    def rank_drafts(
        self,
        drafts: List[str],
        reference: Optional[Dict] = None
    ) -> List[Dict]

    # å¼‚æ­¥æ’åº
    async def rank_drafts_async(
        self,
        drafts: List[str],
        reference: Optional[Dict] = None
    ) -> List[Dict]

    # æ‹’ç»é‡‡æ ·
    def rejection_sampling(
        self,
        drafts: List[str],
        reference: Optional[Dict] = None,
        threshold: float = 70.0,
        max_keep: int = 3
    ) -> List[Dict]

    # å¼‚æ­¥æ‹’ç»é‡‡æ ·
    async def rejection_sampling_async(
        self,
        drafts: List[str],
        reference: Optional[Dict] = None,
        threshold: float = 70.0,
        max_keep: int = 3
    ) -> List[Dict]

    # éªŒè¯äº‹å®å‡†ç¡®æ€§
    def verify_factuality(
        self,
        draft: str,
        evidence: Dict
    ) -> Dict

    # é€‰æ‹©æœ€ä½³è‰ç¨¿
    def select_best_draft(
        self,
        drafts: List[str],
        reference: Optional[Dict] = None
    ) -> Dict
```

### è¿”å›å€¼ç»“æ„

#### evaluate_draft() è¿”å›å€¼

```python
{
    "scores": {
        "coverage": 85,       # è¦†ç›–åº¦
        "factuality": 90,     # å‡†ç¡®æ€§
        "coherence": 80,      # è¿è´¯æ€§
        "academic_style": 88, # å­¦æœ¯æ€§
        "novelty": 75         # æ–°é¢–æ€§
    },
    "overall_score": 84.5,    # æ€»åˆ†
    "strengths": [            # ä¼˜ç‚¹åˆ—è¡¨
        "å¼•ç”¨å…¨é¢",
        "é€»è¾‘æ¸…æ™°"
    ],
    "weaknesses": [           # ç¼ºç‚¹åˆ—è¡¨
        "éƒ¨åˆ†æ®µè½è¿‡é•¿",
        "ç¼ºå°‘æœªæ¥æ–¹å‘"
    ],
    "improvement_suggestions": [  # æ”¹è¿›å»ºè®®
        {
            "issue": "é—®é¢˜æè¿°",
            "suggestion": "æ”¹è¿›å»ºè®®",
            "priority": "high|medium|low"
        }
    ],
    "timestamp": "2024-12-09T10:30:00",
    "draft_length": 1234
}
```

#### verify_factuality() è¿”å›å€¼

```python
{
    "total_claims": 10,           # æ€»é™ˆè¿°æ•°
    "verified_claims": 8,         # å·²éªŒè¯æ•°
    "accuracy_rate": 0.8,         # å‡†ç¡®ç‡
    "unverified_claims": [...],   # æœªéªŒè¯çš„é™ˆè¿°
    "hallucinations": [...],      # å¯èƒ½çš„å¹»è§‰
    "citation_check": {
        "total_citations": 5,
        "invalid_citations": ["paper_999"],
        "citation_validity_rate": 0.8
    }
}
```

---

## ğŸ“ è¾“å…¥æ•°æ®æ ¼å¼

```python
cluster_summaries = {
    "cluster_1": {
        "topic": "ä¸»é¢˜åç§°",
        "summary": "ä¸»é¢˜æ‘˜è¦æè¿°",
        "papers": [
            {
                "paper_id": "å”¯ä¸€æ ‡è¯†",
                "title": "è®ºæ–‡æ ‡é¢˜",
                "authors": ["ä½œè€…1", "ä½œè€…2"],
                "year": 2024,
                "venue": "ä¼šè®®/æœŸåˆŠåç§°",
                "key_contribution": "æ ¸å¿ƒè´¡çŒ®æè¿°",
                "citation_count": 1000  # å¯é€‰
            }
            # æ›´å¤šè®ºæ–‡...
        ]
    },
    "cluster_2": {
        # æ›´å¤šä¸»é¢˜...
    }
}
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•åˆ‡æ¢æ¨¡å‹ï¼Ÿ

```python
# æ–¹æ³• 1: åˆ›å»ºæ—¶æŒ‡å®š
config = ModelConfig(
    name="Qwen-Max",  # åˆ‡æ¢åˆ°é€šä¹‰åƒé—®
    api_key="your-qwen-api-key",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)
writer = WritingAgent(config)

# æ–¹æ³• 2: ä½¿ç”¨é…ç½®æ–‡ä»¶
import json
with open("model_config.json") as f:
    config_data = json.load(f)
    config = ModelConfig(**config_data["models"]["qwen-max"])
```

### Q2: ç”Ÿæˆé€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œï¼š`generate_multiple_candidates_async()`
- é€‰æ‹©æ›´å¿«çš„æ¨¡å‹ï¼šGemini Flash
- å‡å°‘å€™é€‰æ•°é‡ï¼š`num_candidates=3` â†’ `2`
- å‡å°‘ä¿®æ­£è½®æ•°ï¼š`max_iterations=3` â†’ `1`

### Q3: å¦‚ä½•æé«˜ç”Ÿæˆè´¨é‡ï¼Ÿ

**å»ºè®®**ï¼š
- ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹ï¼šQwen-Maxã€Claude Sonnet
- å¢åŠ ä¿®æ­£è½®æ•°ï¼š`max_iterations=3`
- ç”Ÿæˆæ›´å¤šå€™é€‰ï¼š`num_candidates=5`
- æä¾›æ›´è¯¦ç»†çš„è¾“å…¥æ•°æ®
- ä½¿ç”¨è‡ªæˆ‘ä¿®æ­£åŠŸèƒ½

### Q4: API è°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

```python
# æ·»åŠ é‡è¯•æœºåˆ¶
import time

def generate_with_retry(agent, data, max_retries=3):
    for attempt in range(max_retries):
        try:
            return agent.generate_draft(data)
        except Exception as e:
            print(f"å°è¯• {attempt+1} å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                raise
```

### Q5: è¯„åˆ†ä¸ç¨³å®šæ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- é™ä½ Judge Agent çš„ temperatureï¼ˆæ¨è 0.1-0.2ï¼‰
- ä½¿ç”¨å¤šæ¨¡å‹æŠ•ç¥¨å–å¹³å‡
- å¤šæ¬¡è¯„ä¼°å–å¹³å‡å€¼

### Q6: å¦‚ä½•è‡ªå®šä¹‰è¯„åˆ†æƒé‡ï¼Ÿ

```python
from judge_agent import ScoringDimension

# åˆ›å»º Judge
judge = JudgeAgent(config)

# ä¿®æ”¹æƒé‡ï¼ˆä¾‹å¦‚æ›´é‡è§†å‡†ç¡®æ€§ï¼‰
judge.scoring_dimensions["factuality"].weight = 0.40  # æé«˜åˆ° 40%
judge.scoring_dimensions["novelty"].weight = 0.05     # é™ä½åˆ° 5%
```

### Q7: æ”¯æŒå“ªäº›å›½äº§æ¨¡å‹ï¼Ÿ

| æ¨¡å‹ | æä¾›å•† | é€‚ç”¨åœºæ™¯ |
|-----|--------|---------|
| Kimi-K2 | Moonshot | é•¿ä¸Šä¸‹æ–‡ï¼ˆ200Kï¼‰ |
| Qwen-Max | é˜¿é‡Œäº‘ | é«˜è´¨é‡å­¦æœ¯å†™ä½œ |
| DeepSeek-Chat | DeepSeek | æ¨ç†èƒ½åŠ›å¼ºï¼Œæˆæœ¬ä½ |
| GLM-4 | æ™ºè°±AI | ä¸­æ–‡ç†è§£èƒ½åŠ›å¼º |
| Doubao-Pro | å­—èŠ‚è·³åŠ¨ | é€Ÿåº¦å¿«ï¼Œæ€§ä»·æ¯”é«˜ |

---

## ğŸ¯ å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ 1: ç”Ÿæˆ Transformer ç»¼è¿°

```python
# è¾“å…¥æ•°æ®
data = {
    "cluster_1": {
        "topic": "Transformer æ¶æ„ä¸æ³¨æ„åŠ›æœºåˆ¶",
        "summary": "å…³äº Transformer æ¶æ„çš„æå‡ºåŠæ”¹è¿›",
        "papers": [
            {
                "paper_id": "paper_001",
                "title": "Attention is All You Need",
                "authors": ["Vaswani et al."],
                "year": 2017,
                "key_contribution": "æå‡º Transformer æ¶æ„"
            },
            {
                "paper_id": "paper_002",
                "title": "BERT",
                "authors": ["Devlin et al."],
                "year": 2019,
                "key_contribution": "åŒå‘é¢„è®­ç»ƒæ–¹æ³•"
            },
            {
                "paper_id": "paper_003",
                "title": "GPT-3",
                "authors": ["Brown et al."],
                "year": 2020,
                "key_contribution": "å¤§è§„æ¨¡å°‘æ ·æœ¬å­¦ä¹ "
            }
        ]
    }
}

# è¿è¡Œå®Œæ•´æµç¨‹
config = ModelConfig(
    name="Kimi-K2",
    api_key="your-api-key",
    base_url="https://llmapi.paratera.com/v1/"
)

writer = WritingAgent(config)
judge = JudgeAgent(ModelConfig(name="Kimi-K2", api_key="your-api-key",
                                base_url="https://llmapi.paratera.com/v1/",
                                temperature=0.2))

# 1. ç”Ÿæˆå€™é€‰
candidates = writer.generate_multiple_candidates(data, num_candidates=3)

# 2. è¯„ä¼°æ‹©ä¼˜
selected = judge.rejection_sampling(
    drafts=[c["content"] for c in candidates],
    reference=data,
    threshold=70.0
)

# 3. è¾“å‡ºæœ€ä½³
best = selected[0]
print(f"æœ€ä½³è‰ç¨¿å¾—åˆ†: {best['overall_score']:.1f}/100")
print(f"\nè‰ç¨¿å†…å®¹:\n{best['draft']}")

# 4. ä¿å­˜ç»“æœ
with open("transformer_survey.txt", "w", encoding="utf-8") as f:
    f.write(best['draft'])
```

**é¢„æœŸè¾“å‡º**ï¼š
- æ€»åˆ†ï¼š75-85/100
- å‡†ç¡®æ€§ï¼š90+/100
- å¼•ç”¨æœ‰æ•ˆç‡ï¼š100%
- è´¨é‡ç­‰çº§ï¼šè‰¯å¥½-åˆæ ¼

---

## ğŸ“ˆ ç³»ç»Ÿæ€§èƒ½

### æ€§èƒ½æŒ‡æ ‡

**å®Œæ•´æµç¨‹è€—æ—¶**ï¼ˆ3ä¸ªå€™é€‰ï¼‰ï¼š
- ç”Ÿæˆé˜¶æ®µï¼š1-2 åˆ†é’Ÿ
- è¯„ä¼°é˜¶æ®µï¼š1-2 åˆ†é’Ÿ
- æ€»è®¡ï¼š2-4 åˆ†é’Ÿ

**API è°ƒç”¨æ¬¡æ•°**ï¼š
- Writing Agentï¼š3 æ¬¡ï¼ˆ3ä¸ªå€™é€‰ï¼‰
- Judge Agentï¼š4 æ¬¡ï¼ˆ3æ¬¡è¯„åˆ† + 1æ¬¡éªŒè¯ï¼‰
- æ€»è®¡ï¼š7 æ¬¡

**æˆæœ¬ä¼°ç®—**ï¼ˆKimi-K2ï¼‰ï¼š
- è¾“å…¥ tokensï¼š~10K
- è¾“å‡º tokensï¼š~8K
- ä¼°è®¡æˆæœ¬ï¼šÂ¥0.5-1.0

### ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œ**ï¼šé€Ÿåº¦æå‡ 3-5 å€
2. **å®ç°ç»“æœç¼“å­˜**ï¼šèŠ‚çœ 30-50% æˆæœ¬
3. **é€‰æ‹©æ›´å¿«æ¨¡å‹**ï¼šGemini Flash å¯æé€Ÿ 5-10 å€
4. **å‡å°‘å€™é€‰æ•°é‡**ï¼šä» 5 ä¸ªé™åˆ° 3 ä¸ªï¼ŒèŠ‚çœ 40% æ—¶é—´

---

## ğŸ› ï¸ æœ€ä½³å®è·µ

### 1. ç”Ÿæˆé˜¶æ®µ

```python
# æ¨èé…ç½®
candidates = writer.generate_multiple_candidates(
    cluster_summaries=data,
    num_candidates=3-5,           # 3-5 ä¸ªå€™é€‰å³å¯
    temperature_range=(0.3, 0.9)  # æ¸©åº¦èŒƒå›´ä¸è¦å¤ªçª„
)
```

### 2. è¯„ä¼°é˜¶æ®µ

```python
# Judge ä½¿ç”¨ä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
judge_config = ModelConfig(
    name="Kimi-K2",
    temperature=0.2,  # 0.1-0.2 æœ€ä½³
    max_tokens=4096
)
```

### 3. è´¨é‡æ§åˆ¶

```python
# è®¾ç½®åˆç†çš„é˜ˆå€¼
selected = judge.rejection_sampling(
    drafts=candidates,
    threshold=70.0,  # 70-75 æ¯”è¾ƒåˆç†
    max_keep=2-3
)
```

### 4. è¿­ä»£æ”¹è¿›

```python
# åŸºäºåé¦ˆæ”¹è¿›
if best['overall_score'] < 85:
    feedback = {"improvements": best['improvement_suggestions']}
    refined = writer.refine_draft(best['draft'], feedback)
    # é‡æ–°è¯„ä¼°
    final_eval = judge.evaluate_draft(refined["content"])
```

---

## ğŸ“¦ ä¾èµ–è¦æ±‚

- Python >= 3.8
- openai >= 1.0.0

---

## ğŸ”„ åç»­è®¡åˆ’

- [ ] å®ç°åŸºäºåé¦ˆçš„è¿­ä»£æ”¹è¿›å¾ªç¯
- [ ] æ·»åŠ æ›´å¤šæ¨¡å‹æ”¯æŒ
- [ ] å®ç°ç»“æœç¼“å­˜æœºåˆ¶
- [ ] æ”¯æŒæ‰¹é‡å¤„ç†
- [ ] æ·»åŠ å›¾è¡¨ç”ŸæˆåŠŸèƒ½
- [ ] å®ç° Web UI ç•Œé¢

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºå¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯ï¼Œæ„Ÿè°¢ OpenAIã€Anthropicã€é˜¿é‡Œäº‘ã€DeepSeekã€æ™ºè°±AI ç­‰æä¾›çš„ä¼˜ç§€æ¨¡å‹ APIã€‚

---

**æœ€åæ›´æ–°**: 2024-12-09
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
